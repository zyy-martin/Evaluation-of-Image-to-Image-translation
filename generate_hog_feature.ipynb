{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new = {}\n",
    "old = {}\n",
    "with open('horse-to-zebra-dist/train/real_B.txt','r') as f:\n",
    "    for line in f:\n",
    "        line = line.split(',')\n",
    "        new[line[0]] = line[1:]\n",
    "with open('horse-to-zebra-dist/train/real_B_1.txt','r') as f:\n",
    "    for line in f:\n",
    "        line = line.split(',')\n",
    "        old[line[0]] = line[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2,2],[1,3,4]])\n",
    "print (np.argmax(a[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import os\n",
    "\n",
    "def chi_square(x,y):\n",
    "#     x = x / np.sum(x)\n",
    "#     y = y / np.sum(y)\n",
    "    res = 0\n",
    "    for i in range(x.shape[0]):\n",
    "        a = (x[i] - y[i])**2\n",
    "        if a == 0:\n",
    "            continue\n",
    "        a /= (x[i] + y[i])\n",
    "        res += a\n",
    "    return res / 2\n",
    "\n",
    "\n",
    "def get_real(A=True):\n",
    "    if A == True:\n",
    "        real_A = os.listdir('/Users/Martin/Desktop/CS280/finalproj/photo-to-monet-dist/test/real_A')\n",
    "    else:\n",
    "        real_A = os.listdir('/Users/Martin/Desktop/CS280/finalproj/photo-to-monet-dist/test/real_B')\n",
    "    real_A_first_hist = {}\n",
    "    real_A_second_hist = {}\n",
    "\n",
    "    count = 0\n",
    "    A_average_first = np.zeros(32)\n",
    "    A_average_second = np.zeros(32)\n",
    "    for file in real_A:\n",
    "        count += 1\n",
    "        if A == True:\n",
    "            data = scipy.io.loadmat('photo-to-monet-dist/test/real_A/'+file)\n",
    "        else:\n",
    "            data = scipy.io.loadmat('photo-to-monet-dist/test/real_B/'+file)\n",
    "        first_mag = data['mag_first_layer']\n",
    "        second_mag = data['mag_second_layer']\n",
    "        first_ind = data['index_first_layer']\n",
    "        second_ind = data['index_second_layerd']\n",
    "        first = np.ndarray.flatten(first_ind.astype(int))\n",
    "        first, _ = np.histogram(first, bins=32, range=(0,32))\n",
    "        second = np.ndarray.flatten(second_ind.astype(int))\n",
    "        second, _ = np.histogram(first, bins=32, range=(0,32))\n",
    "        real_A_first_hist[file]=first\n",
    "        real_A_second_hist[file]=second\n",
    "        A_average_first += first\n",
    "        A_average_second += second\n",
    "\n",
    "    A_average_first /= count\n",
    "    A_average_second /= count\n",
    "    return real_A_first_hist, real_A_second_hist, A_average_first, A_average_second\n",
    "\n",
    "\n",
    "def get_fake(A=True):\n",
    "    if A == True:\n",
    "        \n",
    "        fake_A = os.listdir('/Users/Martin/Desktop/CS280/finalproj/photo-to-monet-dist/test/fake_A')\n",
    "    else:\n",
    "        fake_A = os.listdir('/Users/Martin/Desktop/CS280/finalproj/photo-to-monet-dist/test/fake_B')\n",
    "    fake_A_first_hist = {}\n",
    "    fake_A_second_hist = {}\n",
    "\n",
    "\n",
    "    A_average_first = np.zeros(32)\n",
    "    A_average_second = np.zeros(32)\n",
    "    for file in fake_A:\n",
    "        if A == True:\n",
    "            data = scipy.io.loadmat('photo-to-monet-dist/test/fake_A/'+file)\n",
    "        else:\n",
    "            data = scipy.io.loadmat('photo-to-monet-dist/test/fake_B/'+file)\n",
    "        first_mag = data['mag_first_layer']\n",
    "        second_mag = data['mag_second_layer']\n",
    "        first_ind = data['index_first_layer']\n",
    "        second_ind = data['index_second_layerd']\n",
    "        first = np.ndarray.flatten(first_ind.astype(int))\n",
    "        first, _ = np.histogram(first, bins=32, range=(0,32))\n",
    "        second = np.ndarray.flatten(second_ind.astype(int))\n",
    "        second, _ = np.histogram(first, bins=32, range=(0,32))\n",
    "        fake_A_first_hist[file]=first\n",
    "        fake_A_second_hist[file]=second\n",
    "    return fake_A_first_hist, fake_A_second_hist\n",
    "\n",
    "def calculate_mean_A(real_A ,average_A):\n",
    "    result = 0\n",
    "    for key in real_A:\n",
    "\n",
    "#         result += scipy.stats.entropy(real_A[key], average_A)\n",
    "  \n",
    "        result += chi_square(real_A[key], average_A)\n",
    "\n",
    "    result /= len(real_A)\n",
    "    return result\n",
    "\n",
    "def calculate_var_A(fake_A, average_A):\n",
    "    KL_div = np.zeros(len(fake_A))\n",
    "    i = 0\n",
    "    for key in fake_A:\n",
    "\n",
    "#         KL_div[i] = scipy.stats.entropy(fake_A[key],average_A)\n",
    "\n",
    "        KL_div[i] = chi_square(fake_A[key], average_A)\n",
    "        i += 1\n",
    "    return np.var(KL_div)\n",
    "\n",
    "\n",
    "def calculate_score(real_A, fake_A, average_A):\n",
    "    keys = fake_A.keys()\n",
    "    result = np.zeros(len(fake_A))\n",
    "    result_m1 = np.zeros(len(fake_A))\n",
    "    i = 0\n",
    "    for key in keys:\n",
    "\n",
    "#         div = scipy.stats.entropy(fake_A[key], average_A)\n",
    "        div = chi_square(fake_A[key], average_A)\n",
    "        mean = calculate_mean_A(real_A, average_A)\n",
    "        var = calculate_var_A(fake_A, average_A)\n",
    "        \n",
    "        m1_score = (div - mean) / var\n",
    "\n",
    "        score = div\n",
    "        result_m1[i] = m1_score\n",
    "        result[i] = score\n",
    "        i += 1\n",
    "#     print(result)\n",
    "    return result, result_m1, keys\n",
    "\n",
    "real_A_first_hist, real_A_second_hist, A_average_first, A_average_second = get_real(False)   \n",
    "fake_A_first_hist, fake_A_second_hist = get_fake(False)\n",
    "first_res_fake_A, first_res_fake_A_m1, key_1_fake_A = calculate_score(real_A_first_hist, fake_A_first_hist, A_average_first)\n",
    "second_res_fake_A, second_res_fake_A_m1, key_2_fake_A  = calculate_score(real_A_second_hist, fake_A_second_hist, A_average_second)\n",
    "first_res_real_A, first_res_real_A_m1, key_1_real_A  = calculate_score(real_A_first_hist, real_A_first_hist, A_average_first)\n",
    "second_res_real_A, second_res_real_A_m1, key_2_real_A  = calculate_score(real_A_second_hist, real_A_second_hist, A_average_second)\n",
    "\n",
    "results = {}\n",
    "results['1_layer_fake_B_keys'] = key_1_fake_A\n",
    "results['2_layer_fake_B_keys'] = key_2_fake_A\n",
    "results['1_layer_fake_B_m1'] = first_res_fake_A_m1\n",
    "results['1_layer_fake_B_chi2'] = first_res_fake_A\n",
    "results['2_layer_fake_B_m1'] = second_res_fake_A_m1\n",
    "results['2_layer_fake_B_chi2'] = second_res_fake_A\n",
    "\n",
    "results['1_layer_real_B_keys'] = key_1_real_A\n",
    "results['2_layer_real_B_keys'] = key_2_real_A\n",
    "results['1_layer_real_B_m1'] = first_res_real_A_m1\n",
    "results['1_layer_real_B_chi2'] = first_res_real_A\n",
    "results['2_layer_real_B_m1'] = second_res_real_A_m1\n",
    "results['2_layer_reak_B_chi2'] = second_res_real_A\n",
    "\n",
    "scipy.io.savemat('B.mat',results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# np.save('1st_layer_B.npy',first_res)\n",
    "# np.save('2nd_layer_B.npy',second_res)\n",
    "\n",
    "# plt.hist(first_res)\n",
    "# plt.xlabel('score')\n",
    "# plt.ylabel('counts')\n",
    "# plt.show()\n",
    "# plt.hist(second_res)\n",
    "# plt.xlabel('score')\n",
    "# plt.ylabel('counts')\n",
    "# plt.show()\n",
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python2]",
   "language": "python",
   "name": "Python [python2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
